## Novel Transformer-Based Architecture which combines Transformer Architecture with CNNs to bring both Spatial and Global Attention.
# Utilized task in creating Facial Recognition AI model
All Layer are built from Scratch and includes
 - transformer architecture
 - Convulational Blocks
 - Multi-Attention Head Blocks
 - ArcFace Layers
 - Sequential Layers
 - Embedding Layers

Performance Metrics Calcualted - ArcFace Loss, Top-1-Accuracy

#Research
Vision Transformer Architecture - https://arxiv.org/pdf/1706.03762
Sequential Layer - https://arxiv.org/pdf/2104.05704
ArcFace - https://arxiv.org/pdf/1801.07698
Transformer Architecture - https://arxiv.org/pdf/1706.03762

#Project Goals
 - To learn and apply the math learned from the research as well as my own unique method to create a Vision Transformer Architecture that can learn both global and local attention in its Multi-Attention-Head Block
